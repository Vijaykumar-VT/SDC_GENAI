{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOBs/fOgB5fbRenVN4OJfbS",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vijaykumar-VT/SDC_GENAI/blob/main/medical_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H1x8f8kUMW3_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "import nltk\n",
        "from nltk.chat.util import Chat, reflections\n",
        "from transformers import pipeline\n",
        "\n",
        "# Define some basic medical queries and responses for NLTK-based chatbot\n",
        "pairs = [\n",
        "    (r\"Hi|Hello|Hey\", [\"Hello! How can I assist you with your health today?\", \"Hi! How can I help you?\"]),\n",
        "    (r\"How are you\\?\", [\"I'm just a chatbot, but I'm doing great! How are you?\"]),\n",
        "    (r\"Tell me about symptoms of flu\",\n",
        "     [\"Flu symptoms usually include fever, chills, body aches, cough, and fatigue.\"]),\n",
        "    (r\"How do I treat a cold\",\n",
        "     [\"For treating a cold, it is important to rest, stay hydrated, and take over-the-counter medications to relieve symptoms.\"]),\n",
        "    (r\"What is COVID-19?\",\n",
        "     [\"COVID-19 is a contagious disease caused by the coronavirus SARS-CoV-2. It can cause symptoms like fever, cough, and shortness of breath.\"]),\n",
        "    (r\"How can I prevent high blood pressure?\",\n",
        "     [\"You can prevent high blood pressure by maintaining a healthy diet, exercising regularly, and managing stress.\"]),\n",
        "    (r\"What should I eat for good health?\",\n",
        "     [\"A balanced diet rich in fruits, vegetables, lean proteins, and whole grains can help you maintain good health.\"]),\n",
        "    (r\"Goodbye\", [\"Goodbye! Stay healthy and take care!\"]),\n",
        "]\n",
        "\n",
        "# Initialize the NLTK-based chatbot with the pairs\n",
        "chatbot = Chat(pairs, reflections)\n",
        "\n",
        "# Initialize Hugging Face's GPT-2 model for advanced responses\n",
        "chatbot_model = pipeline(\"text-generation\", model=\"gpt2\")\n",
        "\n",
        "def medical_chatbot():\n",
        "    print(\"Hello! I am your Medical AI Chatbot. How can I help you today?\")\n",
        "    while True:\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        # Exit the chatbot loop\n",
        "        if user_input.lower() == 'exit' or user_input.lower() == 'quit':\n",
        "            print(\"Goodbye! Stay healthy and take care!\")\n",
        "            break\n",
        "\n",
        "        # Try using NLTK chatbot for basic responses\n",
        "        response = chatbot.respond(user_input)\n",
        "\n",
        "        # If no response from NLTK chatbot, use GPT-2 for an advanced response\n",
        "        if response is None:\n",
        "            response = chatbot_model(user_input, max_length=100, num_return_sequences=1)[0]['generated_text']\n",
        "\n",
        "        print(f\"Bot: {response}\")\n",
        "\n",
        "# Main entry point\n",
        "if __name__ == \"__main__\":\n",
        "    nltk.download('punkt')  # Download required NLTK resources\n",
        "    medical_chatbot()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "4a0ffc72493b44ca978f9e28bd024dd5",
            "c5fb2d4ad454464c904986f7bf9adc14",
            "0e32d9673b934fff8aaf81fe34635fed",
            "636dc1a2928b43f988baac7c9fbbd54a",
            "6b5c57e30bd347d2a219ffa58406a9b3",
            "22e1da9106224be3b3b68a5c23f2f64d",
            "8e0b88b346f345048db11bd6f6c38542",
            "27358e057a0e48eabeebad454f0418d0",
            "12596327da1047c2a4a923934cc35d15",
            "14ddabf3a8e54e2999556425cd196914",
            "94f8aa03cefd4b5a8fbb4a3e1273638c",
            "1da3cbbb39c143dd89fe0908a099903d",
            "bcdc53a0c9204990af0f75a6a9ec86c2",
            "02ed740119ec41979896b0bcab115977",
            "e41621d5fbbd46df9dcadc810b06ad00",
            "32b5a0af814545a1b657eb98a4c06332",
            "daff38f78748428c89ac963aadaad31c",
            "b6eea56773974ec9aa0b0752643ddc13",
            "737d3890b31c4b2a9cc159840d687f10",
            "40d7facbae0346459fcf71f8754308d5",
            "27f35d37d58d4f83b8e450c22ba6c176",
            "ed73a7f164e9443483415aeb8f484a02",
            "7ecf823b3e8c45759b4953e851217ad9",
            "34a012e36f7a4b69b1953d924340d87c",
            "d1dcfbf8db624ccca885ea90d1d56b5f",
            "323a2147184e43959ee2023e22e503a7",
            "3e8192b1d111442a99545ee4b3bce2b2",
            "be370ad0a044476bbda07d4bb5a98d34",
            "119a7c163db349fc89d05ec95884a9d0",
            "84aa14b48b764d53a8c50a9103f3b216",
            "3fc0d488d99e4a48b7804c42f0eb081e",
            "0b6537d9eb6544569f4f9544412e84ee",
            "f5565368b7e94ff19a4264b39f175844",
            "f9badca1d4bc4929bfcd48cf13f0e984",
            "7c23661d2ee84bf493b04ffcc24a2749",
            "6e9015b427b44f858b2213058d0b0f6b",
            "79aad23ac70f4b109fc6a58f5c44f86e",
            "a7f459fd667440039320d3c372ca5186",
            "6cc9de5ab07d4d128471d6402480641c",
            "29abc1ad665c49a99c0a73ae2a7b75b4",
            "13d1935f7b8f45b0888df90460cd64fa",
            "adc80771e32545b2963104c9722cac86",
            "a9c052b48c6c461bba85a8d3de6bdec1",
            "981003a92a4f4a37b211c555b5feb4d9",
            "c04ae502c5de474399391d2e8e2b8964",
            "9f540859b6ff4233ad7548faccca0c09",
            "a236c46e91794796bd49b99a30a77738",
            "e1c24b90c3984a03a8193a4ec1808c71",
            "cb2de88c5a374b64a4bc512eff83bc75",
            "5c09fd51466748aea322f1d64e7c646b",
            "5bafc066314248799ce0797f8e15d6b7",
            "ace5d9ab08e142969a0f96d813087735",
            "bf5969f5ca3b4d54a1dc48596735d1af",
            "82a6b4c924e84c7c9b276ff3cbaa8d5d",
            "7da95e6057f4416f8ba56ee91b2e038e",
            "9344915ac71e43a297b96612eb235de5",
            "f2bf9adbbbf24decafbdfea64f776890",
            "c56d4d932fb24d70ac291004a356c76f",
            "46070c0eb9674dcca0fe1269eb887be4",
            "bcc725a337a24bb5a7e9bbc3c2a14f4f",
            "c3b2ed6eaa6c4c5fb943953f066ffb3c",
            "971cd8f633754dde9d0344206706608b",
            "4aa24a4dd6e847318d981c7da89100b4",
            "b5e352be05074bc6bc7abc501ca91c3c",
            "7f908405e2174cc3b21d0563475bd788",
            "e65679dfc1ce40179dcf8287edf4288b",
            "2200638700634435ae992a25eac2b519",
            "e789ae3f649343e89767455cf75f065c",
            "1da958d4f54b4a23ad3d549223404943",
            "481d2c8ef4de4d60b6f410e90ea63235",
            "e422f3673b6d450795aa16c39142c73e",
            "9b6df702021e4edbb823221c8f8b526a",
            "597607866a5d406596780a2ef157de15",
            "e5a5b6dafa614569991e42de3fddb46c",
            "b6b84a9164e346ebb067ea6b2d3e390d",
            "2ba1639ff8cd4ebf9dedb0e0dd5226ea",
            "7b29d915172a4fd9bf34d3c66dcc9d07"
          ]
        },
        "id": "mvtE1kPHCl69",
        "outputId": "60046410-3665-4651-feba-f4e9cdf864c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "config.json:   0%|          | 0.00/665 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0ffc72493b44ca978f9e28bd024dd5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
            "WARNING:huggingface_hub.file_download:Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "model.safetensors:   0%|          | 0.00/548M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1da3cbbb39c143dd89fe0908a099903d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "generation_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7ecf823b3e8c45759b4953e851217ad9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9badca1d4bc4929bfcd48cf13f0e984"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c04ae502c5de474399391d2e8e2b8964"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9344915ac71e43a297b96612eb235de5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "2200638700634435ae992a25eac2b519"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Device set to use cpu\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hello! I am your Medical AI Chatbot. How can I help you today?\n",
            "You: i feel so tired\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: i feel so tired, the smell of the burning stove, the smell of the burnt bones, the whiff of all the blood and blood… And my God, I just have to say, I feel so old man!\" - John A., Jr., 16\n",
            "\n",
            "\"A nice old man said to me 'I've had a tough time since you left me.' My mother said: What is your daughter doing? Who is she? Is she mad at you? I thought we were friends… \"\n",
            "You: yes\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: yes for a single-payer system without raising taxes. What about our government being a big, bad government. What about a national bank in the sky, with the promise of inflation. What about the fact that everyone is a winner or loser?\n",
            "\n",
            "The answer is a lot more complicated, and it means you'll never be able to prove that.\n",
            "\n",
            "This is why I got started on the question.\n",
            "\n",
            "To illustrate, I've spent a couple of hours explaining to people that it\n",
            "You: what should i have to eat for good health\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: what should i have to eat for good health? So, I do have to eat some of what I might call that 'health food': what are your options on that?\n",
            "\n",
            "Dr. Paul: Right now, I'm eating a lot of meat in order to avoid some problems and to lose weight. I have a lot of things I might eat a little bit more to get rid of the toxins that are on my body.\n",
            "\n",
            "Dr. W.C.D. (In Vit\n",
            "You: 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: 122, or\n",
            "\n",
            "1442, shall have been issued the following year, or\n",
            "\n",
            "1443, may not have been issued as of the end of that calendar year.\n",
            "\n",
            "3. The clerk shall give to all such registrants the name and address of any person in whose name and address any other person may be found on file, or\n",
            "\n",
            "1444, the number of such person, at the same time the records of any of the registrants become available by means of\n",
            "You: something\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: something. He'll never forget his own birthday party. They always have good memories of each other. Never. The only thing wrong with this guy, though? He has only ever had two friends with him. They always had bad memories. Always. And he doesn't even remember his last two outings.\n",
            "\n",
            "There was one time when he went to the gym one morning after the final training session, and his first thought was, \"What day did Jesus have?\" His last thought was he never\n",
            "You: you are not speaking good\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: you are not speaking good English. This is not your father's fault. You must speak well for yourself. Please speak, then, you say. And as you speak, your father will have to come round again. Then you will be back home. Now that you are back home, you must speak. \"I will make them think that if I talk to them,\" said the father, \"if I talk to them, they will tell me why I spoke to you. Therefore the next day\n",
            "You: am telling about you not me\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: am telling about you not me.\n",
            "\n",
            "I asked you what he would do. He told me how good he was and told me how to get there and I told him I liked how he worked. I asked where were you going then when there was one person in your group. I asked him. He told me that I had to go to a place I went back home to find out what the fuck I had come here for. I asked him how long he thought it would take to get\n",
            "You: what is your date of birth\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: what is your date of birth? What is your name? Have you got some fun with your kids?\"\n",
            "\n",
            "\"I was like, why do you have a big, bad name?\"\n",
            "\n",
            "\"I'm all about my daughter. Like my husband, I don't care who he is, I've got to have somebody to make me happy,\" he said. \"I don't just see any name, my daughter is my best friend. My daughter can go to work while my wife does\n",
            "You: bye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: bye can you see my friends? And your dear friend…\n",
            "\n",
            "\"Hello everyone, everyone,\" she whispered, and with a nod she looked up at Mr. Yoo, then off to meet her.\n",
            "\n",
            "\"Come on, how did you know that I was an adult, then?\" she asked, raising her hand and rubbing her forehead.\n",
            "\n",
            "\"Oh, god I know…\" his girlfriend leaned forward to pick her up from his lap. \"You used to call it's\n",
            "You: bye tata\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: bye tata, keh'ya aad.\n",
            "\n",
            "\n",
            "So what's in Aneesan's bag?\n",
            "\n",
            "Aneesan: I'll give them a gift from my brother.\n",
            "\n",
            "Nee-sama...\n",
            "\n",
            "\n",
            "She's here.\n",
            "\n",
            "Nee-sama, what's going on?\n",
            "\n",
            "\n",
            "Nee-sama, what's wrong?\n",
            "\n",
            "Nee-sama, why is Aneesan coming here?\n",
            "\n",
            "Oi-chan, are you not\n",
            "You: ahh\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Bot: ahh was also injured during the attack and died from his injuries at the hospital. The three men of the group were arrested and charged with involvement in the massacre.\n",
            "\n",
            "According to an official statement on the day, Sohail was taken to Tughlal Hospital in Tughlal where he was brought back for further evaluation.\n",
            "\n",
            "Read more:\n",
            "\n",
            "The blast in Darjeeling. A 'cowboy bomb' that targeted Dharamgoda, killing at least\n",
            "You: goodbye\n",
            "Bot: Goodbye! Stay healthy and take care!\n",
            "You: goodbye\n",
            "Bot: Goodbye! Stay healthy and take care!\n",
            "You: bye\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bot: bye to you when you get to the second chapter. You are still on a mission for your job here. You cannot make decisions for others. It's a dangerous job when those people are just waiting for you. You must give up your job before they get what they want. And then it's clear who you are. The same with my job, which is not mine. It is a dream job and I must tell you by now how far I have to go. I love it. If\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "Interrupted by user",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-17-058ce729bceb>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     49\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdownload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'punkt'\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Download required NLTK resources\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m     \u001b[0mmedical_chatbot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-17-058ce729bceb>\u001b[0m in \u001b[0;36mmedical_chatbot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     30\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Hello! I am your Medical AI Chatbot. How can I help you today?\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m         \u001b[0muser_input\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"You: \"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m         \u001b[0;31m# Exit the chatbot loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36mraw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1175\u001b[0m                 \u001b[0;34m\"raw_input was called, but this frontend does not support input requests.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1176\u001b[0m             )\n\u001b[0;32m-> 1177\u001b[0;31m         return self._input_request(\n\u001b[0m\u001b[1;32m   1178\u001b[0m             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprompt\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1179\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parent_ident\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"shell\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/ipykernel/kernelbase.py\u001b[0m in \u001b[0;36m_input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1218\u001b[0m                 \u001b[0;31m# re-raise KeyboardInterrupt, to truncate traceback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1219\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0mKeyboardInterrupt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Interrupted by user\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1220\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1221\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwarning\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Invalid Message:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexc_info\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
          ]
        }
      ]
    }
  ]
}